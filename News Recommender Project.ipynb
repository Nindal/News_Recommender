{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "stemmed_tokens=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('news_articles.csv')\n",
    "df=df[['Article_Id','Title','Content']].dropna()\n",
    "doc_set=list(df['Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4831):\n",
    "    raw=doc_set[i].lower()\n",
    "    raw=re.sub(r'\\d+', '', raw)\n",
    "    word_tokens = tokenizer.tokenize(raw)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    lemmatised_words=[lemmatizer.lemmatize(w) for w in filtered_sentence]\n",
    "    stemmed_words=[stemmer.stem(i) for i in lemmatised_words]\n",
    "    stemmed_tokens.append(stemmed_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nishant/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=corpora.Dictionary(stemmed_tokens)\n",
    "doc_term_matrix=[dictionary.doc2bow(d) for d in stemmed_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=20,minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ldamodel=gensim.models.ldamodel.LdaModel(doc_term_matrix,num_topics=5,id2word=dictionary,passes=20,minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0017065796),\n",
       " (1, 0.001731139),\n",
       " (2, 0.49652022),\n",
       " (3, 0.49834147),\n",
       " (4, 0.001700563)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item=ldamodel[doc_term_matrix[1]]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 5)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=[]\n",
    "for i in range(4831):\n",
    "    item=ldamodel[doc_term_matrix[i]]\n",
    "    item=np.array(item).T\n",
    "    item=item[1]\n",
    "    topics.append(item) \n",
    "\n",
    "np.shape(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_topics(model,num_topics):\n",
    "    word_dict={};\n",
    "    for i in range(num_topics):\n",
    "        words=model.show_topic(i,topn=10);\n",
    "        word_dict['Topic#' + '{:02d}'.format(i+1)]=[i[0] for i in words]\n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic#01</th>\n",
       "      <th>Topic#02</th>\n",
       "      <th>Topic#03</th>\n",
       "      <th>Topic#04</th>\n",
       "      <th>Topic#05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step</td>\n",
       "      <td>india</td>\n",
       "      <td>said</td>\n",
       "      <td>film</td>\n",
       "      <td>featur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instal</td>\n",
       "      <td>year</td>\n",
       "      <td>report</td>\n",
       "      <td>movi</td>\n",
       "      <td>smartphon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android</td>\n",
       "      <td>said</td>\n",
       "      <td>polic</td>\n",
       "      <td>india</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>custom</td>\n",
       "      <td>r</td>\n",
       "      <td>state</td>\n",
       "      <td>also</td>\n",
       "      <td>devic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rom</td>\n",
       "      <td>price</td>\n",
       "      <td>also</td>\n",
       "      <td>khan</td>\n",
       "      <td>camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user</td>\n",
       "      <td>govern</td>\n",
       "      <td>minist</td>\n",
       "      <td>salman</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>devic</td>\n",
       "      <td>market</td>\n",
       "      <td>attack</td>\n",
       "      <td>actor</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>note</td>\n",
       "      <td>crore</td>\n",
       "      <td>peopl</td>\n",
       "      <td>year</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recoveri</td>\n",
       "      <td>compani</td>\n",
       "      <td>govern</td>\n",
       "      <td>releas</td>\n",
       "      <td>galaxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>googl</td>\n",
       "      <td>bank</td>\n",
       "      <td>india</td>\n",
       "      <td>one</td>\n",
       "      <td>xiaomi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic#01 Topic#02 Topic#03 Topic#04   Topic#05\n",
       "0      step    india     said     film     featur\n",
       "1    instal     year   report     movi  smartphon\n",
       "2   android     said    polic    india         gb\n",
       "3    custom        r    state     also      devic\n",
       "4       rom    price     also     khan     camera\n",
       "5      user   govern   minist   salman       also\n",
       "6     devic   market   attack    actor          g\n",
       "7      note    crore    peopl     year        new\n",
       "8  recoveri  compani   govern   releas     galaxi\n",
       "9     googl     bank    india      one     xiaomi"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics(ldamodel,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=np.array(topics)\n",
    "np.shape(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans=sklearn.cluster.KMeans(5).fit(topics)\n",
    "clusters=kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('news_articles.csv')\n",
    "df=df[['Article_Id','Title','Content']].dropna()\n",
    "content=list(df['Content'])\n",
    "title=list(df[\"Title\"])\n",
    "\n",
    "length_article=([len(x) for x in df['Content']] ) #length of articles\n",
    "user_speed=5\n",
    "expected_time=[int((x/5)) for x in length_article]# expected time\n",
    "\n",
    "possion = np.random.poisson(5, 4831)/10 \n",
    "\n",
    "actual_time=expected_time*possion # \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_time1=np.array(expected_time)\n",
    "ratio=actual_time.reshape(4831,1)/expected_time1.reshape(4831,1)\n",
    "ratio=ratio.reshape(4831)\n",
    "click_through= np.random.binomial(1, .8, 4831).reshape(4831)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame({\"Title\":title,\"expected_time\":expected_time,\"actual_time\":actual_time,\"ratio\":ratio,\"click\":click_through})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prof=pd.DataFrame()\n",
    "for i in range(5):\n",
    "    user=data[clusters==i][:1]   \n",
    "    user_prof=user_prof.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=np.array(topics)\n",
    "topics=topics.reshape(4831,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59342319, 0.10164069, 0.10164056, 0.10164658, 0.10164895])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[388]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
