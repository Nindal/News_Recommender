{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "stemmed_tokens=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('news_articles.csv')\n",
    "df=df[['Article_Id','Title','Content']].dropna()\n",
    "doc_set=list(df['Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4831):\n",
    "    raw=doc_set[i].lower()\n",
    "    raw=re.sub(r'\\d+', '', raw)\n",
    "    word_tokens = tokenizer.tokenize(raw)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    lemmatised_words=[lemmatizer.lemmatize(w) for w in filtered_sentence]\n",
    "    stemmed_words=[stemmer.stem(i) for i in lemmatised_words]\n",
    "    stemmed_tokens.append(stemmed_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=corpora.Dictionary(stemmed_tokens)\n",
    "doc_term_matrix=[dictionary.doc2bow(d) for d in stemmed_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=20,minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ldamodel=gensim.models.ldamodel.LdaModel(doc_term_matrix,num_topics=5,id2word=dictionary,passes=20,minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5316874),\n",
       " (1, 0.0017189463),\n",
       " (2, 0.0017448085),\n",
       " (3, 0.0017009544),\n",
       " (4, 0.4631479)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item=ldamodel[doc_term_matrix[1]]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=[]\n",
    "for i in range(4831):\n",
    "    item=ldamodel[doc_term_matrix[i]]\n",
    "    item=np.array(item).T\n",
    "    item=item[1]\n",
    "    topics.append(item) \n",
    "\n",
    "np.shape(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_topics(model,num_topics):\n",
    "    word_dict={};\n",
    "    for i in range(num_topics):\n",
    "        words=model.show_topic(i,topn=10);\n",
    "        word_dict['Topic#' + '{:02d}'.format(i+1)]=[i[0] for i in words]\n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic#01</th>\n",
       "      <th>Topic#02</th>\n",
       "      <th>Topic#03</th>\n",
       "      <th>Topic#04</th>\n",
       "      <th>Topic#05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>devic</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movi</td>\n",
       "      <td>olymp</td>\n",
       "      <td>said</td>\n",
       "      <td>featur</td>\n",
       "      <td>polic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>khan</td>\n",
       "      <td>game</td>\n",
       "      <td>year</td>\n",
       "      <td>android</td>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salman</td>\n",
       "      <td>rio</td>\n",
       "      <td>r</td>\n",
       "      <td>smartphon</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor</td>\n",
       "      <td>world</td>\n",
       "      <td>govern</td>\n",
       "      <td>step</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>releas</td>\n",
       "      <td>indian</td>\n",
       "      <td>price</td>\n",
       "      <td>note</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>also</td>\n",
       "      <td>one</td>\n",
       "      <td>compani</td>\n",
       "      <td>new</td>\n",
       "      <td>peopl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>star</td>\n",
       "      <td>win</td>\n",
       "      <td>market</td>\n",
       "      <td>instal</td>\n",
       "      <td>isi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day</td>\n",
       "      <td>team</td>\n",
       "      <td>modi</td>\n",
       "      <td>gb</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>actress</td>\n",
       "      <td>event</td>\n",
       "      <td>crore</td>\n",
       "      <td>phone</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic#01 Topic#02 Topic#03   Topic#04 Topic#05\n",
       "0     film    india    india      devic     said\n",
       "1     movi    olymp     said     featur    polic\n",
       "2     khan     game     year    android   report\n",
       "3   salman      rio        r  smartphon   attack\n",
       "4    actor    world   govern       step    state\n",
       "5   releas   indian    price       note     also\n",
       "6     also      one  compani        new    peopl\n",
       "7     star      win   market     instal      isi\n",
       "8      day     team     modi         gb     kill\n",
       "9  actress    event    crore      phone     year"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics(ldamodel,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=np.array(topics)\n",
    "np.shape(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans=sklearn.cluster.KMeans(5).fit(topics)\n",
    "clusters=kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1, 0.2, 0.5, ..., 0.3, 0.2, 0.8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('news_articles.csv')\n",
    "df=df[['Article_Id','Title','Content']].dropna()\n",
    "content=list(df['Content'])\n",
    "title=list(df[\"Title\"])\n",
    "\n",
    "length_article=([len(x) for x in df['Content']] ) #length of articles\n",
    "user_speed=5\n",
    "expected_time=[int((x/5)) for x in length_article]# expected time\n",
    "\n",
    "possion = np.random.poisson(5, 4831)/10 \n",
    "\n",
    "actual_time=expected_time*possion # \n",
    "possion        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_time1=np.array(expected_time)\n",
    "ratio=actual_time.reshape(4831,1)/expected_time1.reshape(4831,1)\n",
    "ratio=ratio.reshape(4831)\n",
    "click_through= np.random.binomial(1, .7, 4831).reshape(4831)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=np.array(topics)\n",
    "topics=topics.reshape(4831,5)\n",
    "Topic=pd.DataFrame(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame({\"Title\":title,\"ratio\":ratio,\"click\":click_through,\"estimated\":expected_time,\"actual\":actual_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=pd.DataFrame({\"Weights\":(data[\"click\"]*data[\"ratio\"])})\n",
    "new_data=pd.concat([Topic,weights],axis=1)\n",
    "#weights=np.array(weights).reshape(4831,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prof=pd.DataFrame()\n",
    "n=1\n",
    "for j in range(n):# number of users\n",
    "    for i in range(5):\n",
    "        user=(new_data[clusters==i][j:1+j])\n",
    "        user_prof=user_prof.append(user)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531688</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.463147</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.038464</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.956732</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.050422</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.254641</td>\n",
       "      <td>0.625318</td>\n",
       "      <td>0.040014</td>\n",
       "      <td>0.040014</td>\n",
       "      <td>0.040014</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4  Weights\n",
       "1    0.531688  0.001719  0.001745  0.001701  0.463147      0.2\n",
       "0    0.001621  0.001593  0.038464  0.001590  0.956732      1.1\n",
       "6    0.009832  0.019433  0.919275  0.050422  0.001038      0.8\n",
       "870  0.001477  0.001460  0.001464  0.994143  0.001455      1.0\n",
       "87   0.254641  0.625318  0.040014  0.040014  0.040014      0.3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    user_prof[i]=user_prof[\"Weights\"]*user_prof[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prof=user_prof.drop(\"Weights\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06337583e-01, 3.43789277e-04, 3.48953088e-04, 3.40190926e-04,\n",
       "        9.26294804e-02],\n",
       "       [1.78346663e-03, 1.75195184e-03, 4.23103616e-02, 1.74901985e-03,\n",
       "        1.05240524e+00],\n",
       "       [7.86532685e-03, 1.55466959e-02, 7.35419989e-01, 4.03379619e-02,\n",
       "        8.30002595e-04],\n",
       "       [1.47745607e-03, 1.45954441e-03, 1.46418239e-03, 9.94143486e-01,\n",
       "        1.45529676e-03],\n",
       "       [7.63923436e-02, 1.87595344e-01, 1.20040990e-02, 1.20041091e-02,\n",
       "        1.20041069e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prof=np.array(user_prof)\n",
    "user_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prof=np.array(user_prof)\n",
    "user_prof=user_prof.reshape(n,5,5)\n",
    "new_user=np.sum(user_prof,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_user=user_prof.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_user=np.array(new_user).reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19385618, 0.20669733, 0.79154758, 1.04857477, 1.15932412]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity=cosine_similarity(new_user,topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4831)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67190864, 0.51418251, 0.73603957, ..., 0.59223338, 0.59210953,\n",
       "        0.62546805]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity=np.array(similarity).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity=(similarity).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4831)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top=np.argsort(similarity,axis=1)\n",
    "np.shape(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 574   53 1903 ... 4663 1253 1836]]\n"
     ]
    }
   ],
   "source": [
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top=top[:,-5:]\n",
    "top\n",
    "np.shape(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recom=[]\n",
    "for j in range(n):\n",
    "    for i in range(5):\n",
    "        unu=title[top[j][i]]\n",
    "        new_recom.append(unu)   \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4chan founder Christopher Poole joins Google',\n",
       " 'All mobile phones in India to feature SOS button from March 2016  Govt',\n",
       " 'Uber Ride Gets Bumpier With Ban in New Delhi  Death of Ride Share Model in India ',\n",
       " 'Impossible to unlock new iPhones  Apple tells US court',\n",
       " 'Godrej HIT Announces Nationwide Awareness Campaign on Dengue  Malaria']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
